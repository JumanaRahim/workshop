{
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JumanaRahim/workshop/blob/master/concatenated_resnet_101_and_vgg16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pretrainedmodels\n",
        "!pip install torchsummary\n",
        "!pip install imutils\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jNtZpgFN2p3",
        "outputId": "fdfd3e09-6638-4e4e-dff8-51863728a7c7",
        "execution": {
          "iopub.status.busy": "2022-12-26T12:31:06.838659Z",
          "iopub.execute_input": "2022-12-26T12:31:06.839423Z",
          "iopub.status.idle": "2022-12-26T12:31:53.637058Z",
          "shell.execute_reply.started": "2022-12-26T12:31:06.839312Z",
          "shell.execute_reply": "2022-12-26T12:31:53.635843Z"
        },
        "trusted": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pretrainedmodels in /usr/local/lib/python3.8/dist-packages (0.7.4)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.8/dist-packages (from pretrainedmodels) (2.5.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from pretrainedmodels) (0.14.0+cu116)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from pretrainedmodels) (1.13.0+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from pretrainedmodels) (4.64.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from munch->pretrainedmodels) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->pretrainedmodels) (4.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->pretrainedmodels) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision->pretrainedmodels) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision->pretrainedmodels) (2.25.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->pretrainedmodels) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->pretrainedmodels) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->pretrainedmodels) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->pretrainedmodels) (4.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.8/dist-packages (1.5.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imutils in /usr/local/lib/python3.8/dist-packages (0.5.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6CF3abMats9L",
        "outputId": "2c5b4dca-a222-40a1-ec14-2d3db2dc79f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torchvision import transforms\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torchsummary import summary\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from imutils import paths\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pretrainedmodels\n",
        "import torchvision\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "tvtdq_wwtt_x",
        "execution": {
          "iopub.status.busy": "2022-12-26T12:31:53.640624Z",
          "iopub.execute_input": "2022-12-26T12:31:53.641018Z",
          "iopub.status.idle": "2022-12-26T12:31:59.617932Z",
          "shell.execute_reply.started": "2022-12-26T12:31:53.640986Z",
          "shell.execute_reply": "2022-12-26T12:31:59.616889Z"
        },
        "trusted": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root='/content/drive/MyDrive/JSRT_/dataset/dataset'"
      ],
      "metadata": {
        "id": "mZSWxppaMYV-",
        "execution": {
          "iopub.status.busy": "2022-12-26T12:31:59.619421Z",
          "iopub.execute_input": "2022-12-26T12:31:59.619981Z",
          "iopub.status.idle": "2022-12-26T12:31:59.626541Z",
          "shell.execute_reply.started": "2022-12-26T12:31:59.619941Z",
          "shell.execute_reply": "2022-12-26T12:31:59.625312Z"
        },
        "trusted": true
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes=('benign', 'malignant', 'non-nodule')"
      ],
      "metadata": {
        "id": "Bm74tawRIaTM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths = list(paths.list_images('/content/drive/MyDrive/JSRT_/dataset/dataset'))\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "for img_path in image_paths:\n",
        "    label = img_path.split(os.path.sep)[-2]\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    data.append(img)\n",
        "    labels.append(label)\n",
        "    \n",
        "data = np.array(data)\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "5WDI6i71ORyn",
        "execution": {
          "iopub.status.busy": "2022-12-26T12:31:59.643424Z",
          "iopub.execute_input": "2022-12-26T12:31:59.643809Z",
          "iopub.status.idle": "2022-12-26T12:32:09.491410Z",
          "shell.execute_reply.started": "2022-12-26T12:31:59.643771Z",
          "shell.execute_reply": "2022-12-26T12:32:09.490398Z"
        },
        "trusted": true
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "id": "JRiiXyOerNpE",
        "execution": {
          "iopub.status.busy": "2022-12-26T12:32:09.493186Z",
          "iopub.execute_input": "2022-12-26T12:32:09.493594Z",
          "iopub.status.idle": "2022-12-26T12:32:09.506202Z",
          "shell.execute_reply.started": "2022-12-26T12:32:09.493552Z",
          "shell.execute_reply": "2022-12-26T12:32:09.504740Z"
        },
        "trusted": true,
        "outputId": "3f78cc09-fb3e-48a4-ee6b-7453fb2fbfc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'benign', 'benign', 'benign', 'benign', 'benign',\n",
              "       'benign', 'benign', 'benign', 'benign', 'benign', 'benign',\n",
              "       'benign', 'benign', 'benign', 'benign', 'benign', 'benign',\n",
              "       'benign', 'benign', 'benign', 'benign', 'benign', 'benign',\n",
              "       'benign', 'benign', 'benign', 'benign', 'benign', 'benign',\n",
              "       'benign', 'benign', 'benign', 'benign', 'benign', 'benign',\n",
              "       'benign', 'benign', 'benign', 'benign', 'benign', 'benign',\n",
              "       'benign', 'benign', 'benign', 'benign', 'benign', 'benign',\n",
              "       'benign', 'benign', 'benign', 'benign', 'benign', 'benign',\n",
              "       'benign', 'benign', 'benign', 'benign', 'benign', 'benign',\n",
              "       'benign', 'benign', 'benign', 'benign', 'benign', 'benign',\n",
              "       'benign', 'benign', 'benign', 'benign', 'benign', 'benign',\n",
              "       'benign', 'benign', 'benign', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule'], dtype='<U10')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lb = LabelEncoder()\n",
        "labels = lb.fit_transform(labels)\n",
        "print(f\"Total Number of Classes: {len(lb.classes_)}\")"
      ],
      "metadata": {
        "id": "2TEpv5btiBnH",
        "execution": {
          "iopub.status.busy": "2022-12-26T12:32:09.508190Z",
          "iopub.execute_input": "2022-12-26T12:32:09.508748Z",
          "iopub.status.idle": "2022-12-26T12:32:09.519039Z",
          "shell.execute_reply.started": "2022-12-26T12:32:09.508692Z",
          "shell.execute_reply": "2022-12-26T12:32:09.517642Z"
        },
        "trusted": true,
        "outputId": "9cfdf8d1-f4b3-4b45-d537-d30dd74b8b56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Number of Classes: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#orginal dataset\n",
        "\n",
        "train_orginal_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_orginal_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])    \n",
        "\n",
        "\n",
        "#for data augmentation\n",
        "\n",
        "train_augmentation_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.Normalize(mean = [0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "test_augmentation_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.Normalize(mean = [0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "W2IX6X3ZiwUp",
        "execution": {
          "iopub.status.busy": "2022-12-26T12:32:09.520765Z",
          "iopub.execute_input": "2022-12-26T12:32:09.521177Z",
          "iopub.status.idle": "2022-12-26T12:32:09.533159Z",
          "shell.execute_reply.started": "2022-12-26T12:32:09.521141Z",
          "shell.execute_reply": "2022-12-26T12:32:09.532324Z"
        },
        "trusted": true
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# divide the data into train, validation, and test set\n",
        "#(X, x_val , Y, y_val) = train_test_split(data, labels, test_size=0.2,  stratify=labels,random_state=42)\n",
        "#(x_train, x_test, y_train, y_test) = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
        "#print(f\"x_train examples: {x_train.shape}\\nx_test examples: {x_test.shape}\\nx_val examples: {x_val.shape}\")\n",
        "\n",
        "(x_train, x_test, y_train, y_test) = train_test_split(data, labels, test_size=0.3,random_state=42)\n",
        "print(f\"x_train examples: {x_train.shape}\\nx_test examples: {x_test.shape}\")"
      ],
      "metadata": {
        "id": "Ws76CCyMi6uc",
        "execution": {
          "iopub.status.busy": "2022-12-26T12:32:09.534560Z",
          "iopub.execute_input": "2022-12-26T12:32:09.535019Z",
          "iopub.status.idle": "2022-12-26T12:32:09.551659Z",
          "shell.execute_reply.started": "2022-12-26T12:32:09.534984Z",
          "shell.execute_reply": "2022-12-26T12:32:09.550421Z"
        },
        "trusted": true,
        "outputId": "945b9426-0f51-4249-e735-81371d767f6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train examples: (242, 2048, 2048, 3)\n",
            "x_test examples: (105, 2048, 2048, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=6"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-26T12:32:09.556523Z",
          "iopub.execute_input": "2022-12-26T12:32:09.556808Z",
          "iopub.status.idle": "2022-12-26T12:32:09.561125Z",
          "shell.execute_reply.started": "2022-12-26T12:32:09.556783Z",
          "shell.execute_reply": "2022-12-26T12:32:09.559766Z"
        },
        "trusted": true,
        "id": "nGHs7OMypgHR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# custom dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images, labels, transforms = None):\n",
        "        self.labels = labels\n",
        "        self.images = images\n",
        "        self.transforms = transforms\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        data = self.images[index][:]\n",
        "        labels = self.labels[index]\n",
        "        \n",
        "        if self.transforms:\n",
        "            data = self.transforms(data)\n",
        "            \n",
        "            return data,labels\n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "train_orginal_data = CustomDataset(x_train, y_train, train_orginal_transforms)\n",
        "test_orginal_data = CustomDataset(x_test, y_test, test_orginal_transforms)     \n",
        "\n",
        "\n",
        "train_augmentation_data = CustomDataset(x_train, y_train, train_augmentation_transforms )\n",
        "test_augmentation_data = CustomDataset(x_test, y_test, test_augmentation_transforms )  \n",
        "\n",
        "train_data = torch.utils.data.ConcatDataset([train_orginal_data,train_augmentation_data])\n",
        "print(len(train_data))\n",
        "test_data = torch.utils.data.ConcatDataset([test_orginal_data,test_augmentation_data])\n",
        "print(len(test_data))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "trainLoader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "testLoader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=4) \n"
      ],
      "metadata": {
        "id": "1JI8d5JGjSRG",
        "execution": {
          "iopub.status.busy": "2022-12-26T12:32:09.562790Z",
          "iopub.execute_input": "2022-12-26T12:32:09.563523Z",
          "iopub.status.idle": "2022-12-26T12:32:09.582439Z",
          "shell.execute_reply.started": "2022-12-26T12:32:09.563488Z",
          "shell.execute_reply": "2022-12-26T12:32:09.581347Z"
        },
        "trusted": true,
        "outputId": "0c7fd62b-d687-470d-c209-c852b5775e7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "484\n",
            "210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for X, y in trainLoader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "id": "z47BjF0k7kz7",
        "execution": {
          "iopub.status.busy": "2022-12-26T12:32:09.584106Z",
          "iopub.execute_input": "2022-12-26T12:32:09.584798Z",
          "iopub.status.idle": "2022-12-26T12:32:09.981999Z",
          "shell.execute_reply.started": "2022-12-26T12:32:09.584761Z",
          "shell.execute_reply": "2022-12-26T12:32:09.980469Z"
        },
        "trusted": true,
        "outputId": "67da814a-24ab-42d7-9f28-741452f393b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([6, 3, 224, 224])\n",
            "Shape of y: torch.Size([6]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "id": "dPofmxO_jssC",
        "execution": {
          "iopub.status.busy": "2022-12-26T12:32:09.986556Z",
          "iopub.execute_input": "2022-12-26T12:32:09.987946Z",
          "iopub.status.idle": "2022-12-26T12:32:10.140279Z",
          "shell.execute_reply.started": "2022-12-26T12:32:09.987889Z",
          "shell.execute_reply": "2022-12-26T12:32:10.134832Z"
        },
        "trusted": true,
        "outputId": "ff05b255-e1b3-4241-99c7-48b14fa45511",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODEL**"
      ],
      "metadata": {
        "id": "0DGnW2mEpgHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class vgg16(nn.Module):\n",
        "    def __init__(self, pretrained):\n",
        "        super(vgg16, self).__init__()\n",
        "        if pretrained is True:\n",
        "            self.model = pretrainedmodels.__dict__['vgg16'](pretrained='imagenet')\n",
        "        else:\n",
        "            self.model = pretrainedmodels.__dict__['vgg16'](pretrained = None)\n",
        "        # change the classification layer\n",
        "        #self.l0= nn.Linear(512, len(lb.classes_))\n",
        "        #self.dropout = nn.Dropout2d(0.4)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # get the batch size only, ignore(c, h, w)\n",
        "        #batch, _, _, _ = x.shape\n",
        "        x = self.model.features(x)\n",
        "        #x = F.adaptive_avg_pool2d(x, 1).reshape(batch, -1)\n",
        "        #x = self.dropout(x)\n",
        "        #l0 = self.l0(x)\n",
        "        return x\n",
        "\n",
        "model_1= vgg16(pretrained=True).to(device)\n",
        "print(model_1)"
      ],
      "metadata": {
        "id": "kOPgxghVja4L",
        "execution": {
          "iopub.status.busy": "2022-12-26T12:32:10.144758Z",
          "iopub.execute_input": "2022-12-26T12:32:10.145352Z",
          "iopub.status.idle": "2022-12-26T12:32:23.640406Z",
          "shell.execute_reply.started": "2022-12-26T12:32:10.145313Z",
          "shell.execute_reply": "2022-12-26T12:32:23.639381Z"
        },
        "trusted": true,
        "outputId": "211f2dc4-7887-4a89-cbf1-f189f15ab1b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vgg16(\n",
            "  (model): VGG(\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "    (_features): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (3): ReLU(inplace=True)\n",
            "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (6): ReLU(inplace=True)\n",
            "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (8): ReLU(inplace=True)\n",
            "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (11): ReLU(inplace=True)\n",
            "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (13): ReLU(inplace=True)\n",
            "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (15): ReLU(inplace=True)\n",
            "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (18): ReLU(inplace=True)\n",
            "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (20): ReLU(inplace=True)\n",
            "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (22): ReLU(inplace=True)\n",
            "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (25): ReLU(inplace=True)\n",
            "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (27): ReLU(inplace=True)\n",
            "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (29): ReLU(inplace=True)\n",
            "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (linear0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (relu0): ReLU(inplace=True)\n",
            "    (dropout0): Dropout(p=0.5, inplace=False)\n",
            "    (linear1): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (relu1): ReLU(inplace=True)\n",
            "    (dropout1): Dropout(p=0.5, inplace=False)\n",
            "    (last_linear): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class resnet101(nn.Module):\n",
        "    def __init__(self, pretrained):\n",
        "        super(resnet101, self).__init__()\n",
        "        if pretrained is True:\n",
        "            self.model = pretrainedmodels.__dict__['resnet101'](pretrained='imagenet')\n",
        "        else:\n",
        "            self.model = pretrainedmodels.__dict__['resnet101'](pretrained = None)\n",
        "        # change the classification layer\n",
        "        #self.l0= nn.Linear(512, len(lb.classes_))\n",
        "        #self.dropout = nn.Dropout2d(0.4)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # get the batch size only, ignore(c, h, w)\n",
        "        #batch, _, _, _ = x.shape\n",
        "        x = self.model.features(x)\n",
        "        #x = F.adaptive_avg_pool2d(x, 1).reshape(batch, -1)\n",
        "        #x = self.dropout(x)\n",
        "        #l0 = self.l0(x)\n",
        "        return x\n",
        "\n",
        "model_2= resnet101(pretrained=True).to(device)\n",
        "print(model_2)"
      ],
      "metadata": {
        "id": "LZ3-7Tu5fp-A",
        "execution": {
          "iopub.status.busy": "2022-12-26T12:32:23.641972Z",
          "iopub.execute_input": "2022-12-26T12:32:23.642626Z",
          "iopub.status.idle": "2022-12-26T12:32:30.371884Z",
          "shell.execute_reply.started": "2022-12-26T12:32:23.642581Z",
          "shell.execute_reply": "2022-12-26T12:32:30.370722Z"
        },
        "trusted": true,
        "outputId": "9dd73581-3aa9-42bd-a5f6-c521dd68ea15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resnet101(\n",
            "  (model): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (6): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (7): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (8): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (9): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (10): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (11): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (12): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (13): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (14): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (15): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (16): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (17): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (18): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (19): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (20): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (21): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (22): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): None\n",
            "    (last_linear): Linear(in_features=2048, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyEnsemble(nn.Module):\n",
        "    def __init__(self, model_1, model_2):\n",
        "        super(MyEnsemble, self).__init__()\n",
        "        self.modelA = model_1\n",
        "        self.modelB = model_2\n",
        "        # change the classification layer\n",
        "        self.flatten= nn.Flatten()\n",
        "        self.l0= nn.Linear(104448, len(lb.classes_))\n",
        "        self.dropout = nn.Dropout2d(0.4)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        batch, _, _, _ = x.shape\n",
        "        x1 = self.modelA(x)\n",
        "\n",
        "        #x1 = F.adaptive_avg_pool2d(x11, 1).reshape(batch, -1)\n",
        "\n",
        "        x2 = self.modelB(x)\n",
        "\n",
        "\n",
        "        x_11= self.flatten(x1)\n",
        "        x_22= self.flatten(x2)\n",
        "        concat_1= torch.cat([x_11,x_22],dim=1)\n",
        "\n",
        "        x= concat_1\n",
        "        #x = self.dropout(concat_1)\n",
        "\n",
        "        l0 = self.l0(x)\n",
        "        return l0"
      ],
      "metadata": {
        "id": "sNSx7h46ftxa",
        "execution": {
          "iopub.status.busy": "2022-12-26T12:32:30.373815Z",
          "iopub.execute_input": "2022-12-26T12:32:30.374543Z",
          "iopub.status.idle": "2022-12-26T12:32:30.383942Z",
          "shell.execute_reply.started": "2022-12-26T12:32:30.374499Z",
          "shell.execute_reply": "2022-12-26T12:32:30.382924Z"
        },
        "trusted": true
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= MyEnsemble(model_1, model_2).to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "JricBZwHfx_D",
        "execution": {
          "iopub.status.busy": "2022-12-26T12:32:30.385561Z",
          "iopub.execute_input": "2022-12-26T12:32:30.385984Z",
          "iopub.status.idle": "2022-12-26T12:32:30.907888Z",
          "shell.execute_reply.started": "2022-12-26T12:32:30.385943Z",
          "shell.execute_reply": "2022-12-26T12:32:30.906521Z"
        },
        "trusted": true,
        "outputId": "5521d7cc-d767-48b3-eccd-3a18218a1d63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyEnsemble(\n",
            "  (modelA): vgg16(\n",
            "    (model): VGG(\n",
            "      (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "      (_features): Sequential(\n",
            "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (6): ReLU(inplace=True)\n",
            "        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (8): ReLU(inplace=True)\n",
            "        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (11): ReLU(inplace=True)\n",
            "        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (13): ReLU(inplace=True)\n",
            "        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (15): ReLU(inplace=True)\n",
            "        (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (18): ReLU(inplace=True)\n",
            "        (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (20): ReLU(inplace=True)\n",
            "        (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (22): ReLU(inplace=True)\n",
            "        (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (25): ReLU(inplace=True)\n",
            "        (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (27): ReLU(inplace=True)\n",
            "        (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (29): ReLU(inplace=True)\n",
            "        (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "      (linear0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "      (relu0): ReLU(inplace=True)\n",
            "      (dropout0): Dropout(p=0.5, inplace=False)\n",
            "      (linear1): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "      (relu1): ReLU(inplace=True)\n",
            "      (dropout1): Dropout(p=0.5, inplace=False)\n",
            "      (last_linear): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (modelB): resnet101(\n",
            "    (model): ResNet(\n",
            "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "      (layer1): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer2): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer3): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (4): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (5): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (6): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (7): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (8): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (9): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (10): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (11): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (12): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (13): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (14): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (15): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (16): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (17): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (18): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (19): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (20): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (21): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (22): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer4): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "      (fc): None\n",
            "      (last_linear): Linear(in_features=2048, out_features=1000, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (l0): Linear(in_features=104448, out_features=3, bias=True)\n",
            "  (dropout): Dropout2d(p=0.4, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = MyEnsemble(model_1, model_2).to(device)\n",
        "\n",
        "#model.load_state_dict(torch.load(\"/kaggle/working/model.pth\", map_location= device))\n",
        "\n",
        "model.to(device)\n",
        "summary(model, (3, 224, 224))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-26T12:32:30.909739Z",
          "iopub.execute_input": "2022-12-26T12:32:30.910475Z",
          "iopub.status.idle": "2022-12-26T12:32:41.933278Z",
          "shell.execute_reply.started": "2022-12-26T12:32:30.910431Z",
          "shell.execute_reply": "2022-12-26T12:32:41.930947Z"
        },
        "trusted": true,
        "id": "dxFcjzADpgHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **OPTIMZER**"
      ],
      "metadata": {
        "id": "wZc2KHeFpgHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "\n",
        "WEIGHT_DECAY = 0.0005\n",
        "save_path = \"model.pth\"\n",
        "fine_tune = True\n",
        "#load_path = \"/kaggle/working/model_1.pth\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-26T12:32:41.934475Z",
          "iopub.execute_input": "2022-12-26T12:32:41.934886Z",
          "iopub.status.idle": "2022-12-26T12:32:41.951097Z",
          "shell.execute_reply.started": "2022-12-26T12:32:41.934847Z",
          "shell.execute_reply": "2022-12-26T12:32:41.945887Z"
        },
        "trusted": true,
        "id": "I32hU__mpgHj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr = lr, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#optimizer_1= torch.optim.SGD(model_1.parameters(),lr= lr,momentum=0.9)\n",
        "#optimizer_2= torch.optim.SGD(model_2.parameters(),lr= lr,momentum=0.9)\n",
        "#optimizer= torch.optim.SGD(model.parameters(),lr= lr,momentum=0.9)\n",
        "\n",
        "params = list(model_1.parameters()) + list(model_2.parameters())\n",
        "#optimizer = optim.SGD(params, lr=learning_rate)\n",
        "\n",
        "\n",
        "optimizer= torch.optim.SGD(params, lr= lr, momentum=0.9)"
      ],
      "metadata": {
        "id": "_BoLGPxjMDVW",
        "execution": {
          "iopub.status.busy": "2022-12-26T12:32:41.952141Z",
          "iopub.execute_input": "2022-12-26T12:32:41.952717Z",
          "iopub.status.idle": "2022-12-26T12:32:41.970151Z",
          "shell.execute_reply.started": "2022-12-26T12:32:41.952665Z",
          "shell.execute_reply": "2022-12-26T12:32:41.966381Z"
        },
        "trusted": true
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LOAD MODEL**"
      ],
      "metadata": {
        "id": "0-fx6fGPpgHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#state_dict = torch.load(load_path, map_location=device)\n",
        "#model.load_state_dict(state_dict)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-26T12:32:41.971391Z",
          "iopub.execute_input": "2022-12-26T12:32:41.971785Z",
          "iopub.status.idle": "2022-12-26T12:32:41.983300Z",
          "shell.execute_reply.started": "2022-12-26T12:32:41.971749Z",
          "shell.execute_reply": "2022-12-26T12:32:41.980064Z"
        },
        "trusted": true,
        "id": "F1YJU0mKpgHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRAINING**"
      ],
      "metadata": {
        "id": "WuY1-skYpgHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,dataloader):    \n",
        "    # training function\n",
        "\n",
        "    print('Training')\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_correct = 0\n",
        "    total=0\n",
        "    for batch, (X, y) in enumerate(tqdm(dataloader)):\n",
        "\n",
        "\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X)\n",
        "        loss = loss_fn(outputs, y)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        running_correct += (outputs.argmax(1) == y).type(torch.float).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    loss = running_loss/len(dataloader)\n",
        "    accuracy = 100.*running_correct/total\n",
        "    print('Train Loss: %.3f | Accuracy: %.3f'%(loss, accuracy))\n",
        "\n",
        "\n",
        "    #print(f\"Train Loss: {loss:.4f}, Train Acc: {accuracy:.2f}\")\n",
        "\n",
        "\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-26T12:32:41.984740Z",
          "iopub.execute_input": "2022-12-26T12:32:41.985056Z",
          "iopub.status.idle": "2022-12-26T12:32:42.007420Z",
          "shell.execute_reply.started": "2022-12-26T12:32:41.985025Z",
          "shell.execute_reply": "2022-12-26T12:32:42.004386Z"
        },
        "trusted": true,
        "id": "NzftM9uQpgHl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **VALIDATION**"
      ],
      "metadata": {
        "id": "yZ7ivbFypgHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#validation function\n",
        "def validate(model, dataloader):\n",
        "    print('Validating')\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_correct = 0\n",
        "    total=0\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # Compute prediction error\n",
        "            pred = model(X)\n",
        "            loss = loss_fn(pred, y)\n",
        "            running_loss += loss_fn(pred, y).item()        \n",
        "            running_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            total += y.size(0)\n",
        "        \n",
        "    loss = running_loss/len(dataloader)\n",
        "    accuracy = 100.*running_correct/total\n",
        "    #print(f'Val Loss: {loss:.4f}, Val Acc: {accuracy:.2f}')\n",
        "    print('Test Loss: %.3f | Accuracy: %.3f'%(loss, accuracy))\n",
        "\n",
        "\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "id": "fzPzLoCBpThK",
        "execution": {
          "iopub.status.busy": "2022-12-26T12:32:42.008367Z",
          "iopub.execute_input": "2022-12-26T12:32:42.008731Z",
          "iopub.status.idle": "2022-12-26T12:32:42.023510Z",
          "shell.execute_reply.started": "2022-12-26T12:32:42.008697Z",
          "shell.execute_reply": "2022-12-26T12:32:42.022705Z"
        },
        "trusted": true
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRAINING AND VALIDATION IN SINGLE FUNCTION**"
      ],
      "metadata": {
        "id": "Cn1RGyE-pgHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=50\n",
        "\n",
        "\n",
        "train_loss , train_accuracy = [], []\n",
        "val_loss , val_accuracy = [], []\n",
        "print(f\"Training on {len(train_data)} examples, validating on {len(test_data)} examples...\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch+1} of {epochs}\")\n",
        "    train_epoch_loss, train_epoch_accuracy = train(model, trainLoader)\n",
        "    val_epoch_loss, val_epoch_accuracy = validate(model, testLoader)\n",
        "    train_loss.append(train_epoch_loss)\n",
        "    train_accuracy.append(train_epoch_accuracy)\n",
        "    val_loss.append(val_epoch_loss)\n",
        "    val_accuracy.append(val_epoch_accuracy)\n"
      ],
      "metadata": {
        "id": "YbdqtXP0rBQI",
        "execution": {
          "iopub.status.busy": "2022-12-26T12:32:42.025040Z",
          "iopub.execute_input": "2022-12-26T12:32:42.025721Z",
          "iopub.status.idle": "2022-12-26T13:19:44.069331Z",
          "shell.execute_reply.started": "2022-12-26T12:32:42.025685Z",
          "shell.execute_reply": "2022-12-26T13:19:44.067790Z"
        },
        "trusted": true,
        "outputId": "163c575e-1730-49c9-87af-2ca10c1feb97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on 484 examples, validating on 210 examples...\n",
            "Epoch 1 of 50\n",
            "Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/81 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODEL SAVING**"
      ],
      "metadata": {
        "id": "Ne_0FQUqpgHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), save_path)\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-26T13:19:44.071102Z",
          "iopub.execute_input": "2022-12-26T13:19:44.071929Z",
          "iopub.status.idle": "2022-12-26T13:19:46.265259Z",
          "shell.execute_reply.started": "2022-12-26T13:19:44.071875Z",
          "shell.execute_reply": "2022-12-26T13:19:46.264175Z"
        },
        "trusted": true,
        "id": "V_p55etxpgHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyEnsemble(model_1, model_2).to(device)\n",
        "#model.load_state_dict(torch.load(\"model.pth\"))\n",
        "\n",
        "state_dict = torch.load(f\"/kaggle/working/{save_path}\")\n",
        "model.load_state_dict(state_dict)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-26T13:19:46.269245Z",
          "iopub.execute_input": "2022-12-26T13:19:46.271827Z",
          "iopub.status.idle": "2022-12-26T13:19:47.241888Z",
          "shell.execute_reply.started": "2022-12-26T13:19:46.271790Z",
          "shell.execute_reply": "2022-12-26T13:19:47.240790Z"
        },
        "trusted": true,
        "id": "gG9Dz3s1pgHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **VISUALIZE PREDICTING IMAGE**"
      ],
      "metadata": {
        "id": "bkYpSiLdpgHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Function to show the images\n",
        "def imageshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Function to test the model with a batch of images and show the labels predictions\n",
        "def testBatch():\n",
        "    # get batch of images from the test DataLoader  \n",
        "    images, labels = next(iter(testLoader))\n",
        "\n",
        "    # show all images as one image grid\n",
        "    imageshow(torchvision.utils.make_grid(images))\n",
        "   \n",
        "    # Show the real labels on the screen \n",
        "    print('Real labels: ', ' '.join('%5s' % classes[labels[j]] \n",
        "                               for j in range(batch_size)))\n",
        "  \n",
        "    # Let's see what if the model identifiers the  labels of those example\n",
        "    images=images.to(device)\n",
        "    outputs = model(images)\n",
        "    \n",
        "    # We got the probability for every 10 labels. The highest (max) probability should be correct label\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    \n",
        "    # Let's show the predicted labels on the screen to compare with the real ones\n",
        "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] \n",
        "                              for j in range(batch_size)))"
      ],
      "metadata": {
        "id": "RStsMLZvrBNa",
        "execution": {
          "iopub.status.busy": "2022-12-26T13:19:47.243573Z",
          "iopub.execute_input": "2022-12-26T13:19:47.243945Z",
          "iopub.status.idle": "2022-12-26T13:19:47.253441Z",
          "shell.execute_reply.started": "2022-12-26T13:19:47.243907Z",
          "shell.execute_reply": "2022-12-26T13:19:47.252215Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testBatch()"
      ],
      "metadata": {
        "id": "PgWaYFytpTZM",
        "execution": {
          "iopub.status.busy": "2022-12-26T13:19:47.260257Z",
          "iopub.execute_input": "2022-12-26T13:19:47.260566Z",
          "iopub.status.idle": "2022-12-26T13:19:48.142085Z",
          "shell.execute_reply.started": "2022-12-26T13:19:47.260539Z",
          "shell.execute_reply": "2022-12-26T13:19:48.140754Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PLOT ACCURACY**"
      ],
      "metadata": {
        "id": "AQi4nZDwpgHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy plots\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.subplot(121)\n",
        "plt.plot(train_accuracy, color='green', label='train accuracy')\n",
        "plt.plot(val_accuracy, color='blue', label='validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "# plt.savefig('../outputs/plots/accuracy.png')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-26T13:19:48.144611Z",
          "iopub.execute_input": "2022-12-26T13:19:48.145361Z",
          "iopub.status.idle": "2022-12-26T13:19:48.398762Z",
          "shell.execute_reply.started": "2022-12-26T13:19:48.145307Z",
          "shell.execute_reply": "2022-12-26T13:19:48.397661Z"
        },
        "trusted": true,
        "id": "PMSTl1f3pgHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PLOT LOSS**"
      ],
      "metadata": {
        "id": "hBH_sqH_pgHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loss plots\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.subplot(121)\n",
        "plt.plot(train_loss, color='orange', label='train loss')\n",
        "plt.plot(val_loss, color='red', label='validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "# plt.savefig('../outputs/plots/loss.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-26T13:19:48.400229Z",
          "iopub.execute_input": "2022-12-26T13:19:48.400598Z",
          "iopub.status.idle": "2022-12-26T13:19:48.629637Z",
          "shell.execute_reply.started": "2022-12-26T13:19:48.400560Z",
          "shell.execute_reply": "2022-12-26T13:19:48.628587Z"
        },
        "trusted": true,
        "id": "qJ6iRTp4pgHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pv-el0cSpgHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label2class ={ 1 :'001', 2 :'002', 3:'003', 4:'004', 5:'005', 6:'006', 7:'007', 8:'008', 9:'009', 10:'010', 11:'011', 12:'012', 13:'013', 14:'014', 15:'015', 16:'016', 17:'017', 18:'018', 19:'019', 20:'020', 21:'021', 22:'022', 23:'023', 24:'024', 25:'025', 26:'026', 27:'027', 28:'028', 29:'029', 30:'030', 31:'031', 32:'032', 33:'033', 34:'034', 35:'035', 36:'036', 37:'037', 38:'038', 39:'039', 40:'040', 41:'041', 42:'042', 43:'043', 44:'044', 45:'045',46:'046', 47:'047', 48:'048', 49:'049', 50:'050', 51:'051', 52:'052', 53:'053', 54:'054',55:'055', 56:'056', 57:'057', 58:'058', 59:'059', 60:'060', 61:'061', 62:'062', 63:'063',64:'064', 65:'065', 66:'066', 67:'067', 68:'068', 69:'069', 70:'070', 71:'071', 72:'072',73:'073', 74:'074', 75:'075', 76:'076', 77:'077', 78:'078', 79:'079', 80:'080', 81:'081', 82:'082', 83:'083', 84:'084', 85:'085', 86:'086', 87:'087', 88:'088', 89:'089', 90:'090',91:'091', 92:'092', 93:'093', 94:'094', 95:'095', 96:'096', 97:'097', 98:'098', 99:'099', 100:'100', 101:'101', 102:'102', 103:'103', 104:'104', 105:'105', 106:'106', 107:'107', 108:'108', 109:'109', 110:'110', 111:'111', 112:'112', 113:'113', 114:'114', 115:'115', 116:'116', 117:'117',118:'118', 119:'119', 120:'120', 121:'121', 122:'122', 123:'123', 124:'124', 125:'125', 126:'126',127:'127', 128:'128', 129:'129', 130:'130', 131:'131', 132:'132', 133:'133', 134:'134', 135:'135',136:'136', 137:'137', 138:'138', 139:'139', 140:'140', 141:'141', 142:'142', 143:'143', 144:'144',145:'145', 146:'146', 147:'147', 148:'148', 149:'149', 150:'150', 151:'151', 152:'152', 153:'153',154:'154', 155:'155', 156:'156', 157:'157', 158:'158'}\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-26T13:19:48.631369Z",
          "iopub.execute_input": "2022-12-26T13:19:48.632113Z",
          "iopub.status.idle": "2022-12-26T13:19:48.647842Z",
          "shell.execute_reply.started": "2022-12-26T13:19:48.632070Z",
          "shell.execute_reply": "2022-12-26T13:19:48.646772Z"
        },
        "trusted": true,
        "id": "1MWYP8_1pgHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns \n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "# iterate over test data\n",
        "for batch,(inputs, labels) in enumerate(testLoader):\n",
        "    \n",
        "    \n",
        "        inputs= inputs.to(device)\n",
        "        labels= labels.to(device)\n",
        "        output = model(inputs) # Feed Network\n",
        "\n",
        "        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
        "        y_pred.extend(output) # Save Prediction\n",
        "        \n",
        "        labels = labels.data.cpu().numpy()\n",
        "        y_true.extend(labels) # Save Truth\n",
        "        \n",
        "        \n",
        "\n",
        "report = classification_report(y_true, y_pred)\n",
        "print(report)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-26T13:19:48.649546Z",
          "iopub.execute_input": "2022-12-26T13:19:48.650069Z",
          "iopub.status.idle": "2022-12-26T13:19:55.809435Z",
          "shell.execute_reply.started": "2022-12-26T13:19:48.650030Z",
          "shell.execute_reply": "2022-12-26T13:19:55.808217Z"
        },
        "trusted": true,
        "id": "JoM3LligpgHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_classes = 158\n",
        "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(testLoader):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "plt.figure(figsize=(100,100))\n",
        "\n",
        "class_names = list(label2class.values())\n",
        "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
        "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-26T13:19:55.813879Z",
          "iopub.execute_input": "2022-12-26T13:19:55.818003Z",
          "iopub.status.idle": "2022-12-26T13:21:31.200397Z",
          "shell.execute_reply.started": "2022-12-26T13:19:55.817930Z",
          "shell.execute_reply": "2022-12-26T13:21:31.199278Z"
        },
        "trusted": true,
        "id": "vEObx_JGpgHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pdA0MFHipgHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k-7PiQ_2pgHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LmjiUVjppgHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gMH940oIpgHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eteOdOgxpgHt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}