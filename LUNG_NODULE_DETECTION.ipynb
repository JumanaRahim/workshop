{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/JumanaRahim/workshop/blob/master/LUNG_NODULE_DETECTION.ipynb",
      "authorship_tag": "ABX9TyPm0vqCTVGvVACtr7oFsF7g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JumanaRahim/workshop/blob/master/LUNG_NODULE_DETECTION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl-U3pVwFt6t",
        "outputId": "3595ef4a-36b1-4155-c03b-21c59b16f527"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pretrainedmodels\n",
        "!pip install torchsummary\n",
        "!pip install imutils\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vnl_dl-Z3OYy",
        "outputId": "8c990ee4-81ba-4105-bd1e-8efae658ce5c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pretrainedmodels in /usr/local/lib/python3.8/dist-packages (0.7.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from pretrainedmodels) (4.64.1)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.8/dist-packages (from pretrainedmodels) (2.5.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from pretrainedmodels) (0.14.0+cu116)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from pretrainedmodels) (1.13.0+cu116)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from munch->pretrainedmodels) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->pretrainedmodels) (4.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->pretrainedmodels) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision->pretrainedmodels) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision->pretrainedmodels) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->pretrainedmodels) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->pretrainedmodels) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->pretrainedmodels) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->pretrainedmodels) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.8/dist-packages (1.5.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imutils in /usr/local/lib/python3.8/dist-packages (0.5.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torchvision import transforms\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torchsummary import summary\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from imutils import paths\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pretrainedmodels\n",
        "import torchvision\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "dFzpFj4zF7vo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root='/content/drive/MyDrive/JSRT_/dataset/dataset'"
      ],
      "metadata": {
        "id": "5gtt2CuJ3h3X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes=('benign','malignant','non-nodule')"
      ],
      "metadata": {
        "id": "lBWCXdWW4p8h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths = list(paths.list_images('/content/drive/MyDrive/JSRT_/dataset/dataset'))\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "for img_path in image_paths:\n",
        "    label = img_path.split(os.path.sep)[-2]\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    data.append(img)\n",
        "    labels.append(label)\n",
        "    \n",
        "data = np.array(data)\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "5yBbc2kaG-yw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnudlXjW40vW",
        "outputId": "48c88ba3-19c8-422e-953c-fac99ae56c69"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'non-nodule', 'non-nodule', 'non-nodule',\n",
              "       'non-nodule', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'malignant', 'malignant', 'malignant', 'malignant',\n",
              "       'malignant', 'benign', 'benign', 'benign', 'benign', 'benign',\n",
              "       'benign', 'benign', 'benign', 'benign', 'benign', 'benign',\n",
              "       'benign', 'benign', 'benign', 'benign', 'benign', 'benign',\n",
              "       'benign', 'benign', 'benign', 'benign', 'benign', 'benign',\n",
              "       'benign', 'benign', 'benign', 'benign', 'benign', 'benign',\n",
              "       'benign', 'benign', 'benign', 'benign', 'benign', 'benign',\n",
              "       'benign', 'benign', 'benign', 'benign', 'benign', 'benign',\n",
              "       'benign', 'benign', 'benign', 'benign', 'benign', 'benign',\n",
              "       'benign', 'benign', 'benign', 'benign', 'benign', 'benign',\n",
              "       'benign'], dtype='<U10')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lb = LabelEncoder()\n",
        "labels = lb.fit_transform(labels)\n",
        "print(f\"Total Number of Classes: {len(lb.classes_)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fRfl8aM44Hv",
        "outputId": "11b42fa5-b868-48cc-c506-a7587e32b112"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Number of Classes: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((126, 126)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5)])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((126, 126)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5)]) "
      ],
      "metadata": {
        "id": "MJCgs3a549v7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# divide the data into train, validation, and test set\n",
        "(X, x_val , Y, y_val) = train_test_split(data, labels, test_size=0.2,  stratify=labels,random_state=42)\n",
        "(x_train, x_test, y_train, y_test) = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
        "print(f\"x_train examples: {x_train.shape}\\nx_test examples: {x_test.shape}\\nx_val examples: {x_val.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CG1Y6fS5Hu7",
        "outputId": "7211ba36-0b84-408a-c654-7e07e38e8914"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train examples: (147, 2048, 2048, 3)\n",
            "x_test examples: (50, 2048, 2048, 3)\n",
            "x_val examples: (50, 2048, 2048, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32"
      ],
      "metadata": {
        "id": "XW-b8LEM5QFn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# custom dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images, labels, transforms = None):\n",
        "        self.labels = labels\n",
        "        self.images = images\n",
        "        self.transforms = transforms\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        data = self.images[index][:]\n",
        "        labels = self.labels[index]\n",
        "        \n",
        "        if self.transforms:\n",
        "            data = self.transforms(data)\n",
        "            \n",
        "            return data,labels\n",
        "\n",
        "train_data = CustomDataset(x_train, y_train, train_transforms)\n",
        "val_data = CustomDataset(x_val, y_val, val_transform)\n",
        "test_data = CustomDataset(x_test, y_test, val_transform)       \n",
        "\n",
        "trainLoader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=4)\n",
        "valLoader = DataLoader(val_data, batch_size=32, shuffle=True, num_workers=4)\n",
        "testLoader = DataLoader(test_data, batch_size=32, shuffle=True, num_workers=4) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TMxHWPW5Xr-",
        "outputId": "a93baf8e-a824-4d3d-967f-4f448e8cf56e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for X, y in trainLoader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yG7Kecz5ZfV",
        "outputId": "36f4a959-94c5-4ce9-cee1-7a2ddbe3f0fa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([32, 3, 126, 126])\n",
            "Shape of y: torch.Size([32]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFej9Nwn5fY6",
        "outputId": "75dbc7f6-4168-449a-881c-ae7328f034de"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = torch.nn.Sequential(\n",
        "            #Input = 3 x 32 x 32, Output = 32 x 32 x 32\n",
        "            torch.nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 3, padding = 1), \n",
        "            torch.nn.ReLU(),\n",
        "            #Input = 32 x 32 x 32, Output = 32 x 16 x 16\n",
        "            torch.nn.MaxPool2d(kernel_size=2),\n",
        "  \n",
        "            #Input = 32 x 16 x 16, Output = 64 x 16 x 16\n",
        "            torch.nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, padding = 1),\n",
        "            torch.nn.ReLU(),\n",
        "            #Input = 64 x 16 x 16, Output = 64 x 8 x 8\n",
        "            torch.nn.MaxPool2d(kernel_size=2),\n",
        "              \n",
        "            #Input = 64 x 8 x 8, Output = 64 x 8 x 8\n",
        "            torch.nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, padding = 1),\n",
        "            torch.nn.ReLU(),\n",
        "            #Input = 64 x 8 x 8, Output = 64 x 4 x 4\n",
        "            torch.nn.MaxPool2d(kernel_size=2),\n",
        "  \n",
        "            torch.nn.Flatten(),\n",
        "            torch.nn.Linear(64*4*4, 512),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(512, 10)\n",
        "        )\n",
        "  \n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "RNMQTF_XXT5T"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Selecting the appropriate training device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = CNN().to(device)\n",
        "  \n",
        "#Defining the model hyper parameters\n",
        "num_epochs = 50\n",
        "learning_rate = 0.001\n",
        "weight_decay = 0.01\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "  \n",
        "#Training process begins\n",
        "train_loss_list = []\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}:', end = ' ')\n",
        "    train_loss = 0\n",
        "      \n",
        "    #Iterating over the training dataset in batches\n",
        "    model.train()\n",
        "    for i, (images, labels) in enumerate(trainLoader):\n",
        "          \n",
        "        #Extracting images and target labels for the batch being iterated\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "  \n",
        "        #Calculating the model output and the cross entropy loss\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "  \n",
        "        #Updating weights according to calculated loss\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "      \n",
        "    #Printing loss for each epoch\n",
        "    train_loss_list.append(train_loss/len(train_loader))\n",
        "    print(f\"Training loss = {train_loss_list[-1]}\")   \n",
        "      \n",
        "#Plotting loss for all epochs\n",
        "plt.plot(range(1,num_epochs+1), train_loss_list)\n",
        "plt.xlabel(\"Number of epochs\")\n",
        "plt.ylabel(\"Training loss\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "Wuuaa6j-Xh3p",
        "outputId": "a31f83c4-2521-4f64-94da-1e45bc76af97"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-bebdd8deb34b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#Calculating the model output and the cross entropy loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-1b1844c95f8b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x14400 and 1024x512)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile the model\n",
        "cnn.compile(optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "RynBkEcvShTY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,dataloader):    \n",
        "    # training function\n",
        "\n",
        "    print('Training')\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_correct = 0\n",
        "    total=0\n",
        "    for batch, (X, y) in enumerate(tqdm(dataloader)):\n",
        "\n",
        "\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X)\n",
        "        loss = loss_fn(outputs, y)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        running_correct += (outputs.argmax(1) == y).type(torch.float).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    loss = running_loss/len(dataloader)\n",
        "    accuracy = 100.*running_correct/total\n",
        "    print('Train Loss: %.3f | Accuracy: %.3f'%(loss, accuracy))\n",
        "\n",
        "\n",
        "    #print(f\"Train Loss: {loss:.4f}, Train Acc: {accuracy:.2f}\")\n",
        "\n",
        "\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "id": "tAFFeSDMG-65"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#validation function\n",
        "def validate(model, dataloader):\n",
        "    print('Validating')\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_correct = 0\n",
        "    total=0\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # Compute prediction error\n",
        "            pred = model(X)\n",
        "            loss = loss_fn(pred, y)\n",
        "            running_loss += loss_fn(pred, y).item()        \n",
        "            running_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            total += y.size(0)\n",
        "        \n",
        "    loss = running_loss/len(dataloader)\n",
        "    accuracy = 100.*running_correct/total\n",
        "    #print(f'Val Loss: {loss:.4f}, Val Acc: {accuracy:.2f}')\n",
        "    print('Test Loss: %.3f | Accuracy: %.3f'%(loss, accuracy))\n",
        "\n",
        "\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "id": "XIsYMzi4IxS2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "WEIGHT_DECAY = 0.0005\n",
        "fine_tune = True\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr = lr, weight_decay=WEIGHT_DECAY)\n",
        "optimizer= torch.optim.SGD(model.parameters(),lr= lr,momentum=0.9)"
      ],
      "metadata": {
        "id": "-66k3Q7oMVU4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=50\n",
        "\n",
        "\n",
        "train_loss , train_accuracy = [], []\n",
        "val_loss , val_accuracy = [], []\n",
        "print(f\"Training on {len(train_data)} examples, validating on {len(test_data)} examples...\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch+1} of {epochs}\")\n",
        "    train_epoch_loss, train_epoch_accuracy = train(model, trainLoader)\n",
        "    val_epoch_loss, val_epoch_accuracy = validate(model, testLoader)\n",
        "    train_loss.append(train_epoch_loss)\n",
        "    train_accuracy.append(train_epoch_accuracy)\n",
        "    val_loss.append(val_epoch_loss)\n",
        "    val_accuracy.append(val_epoch_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "UY3ezrK2HJwj",
        "outputId": "abc2dbbe-250e-4612-ee80-1c9ab81bd002"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on 147 examples, validating on 50 examples...\n",
            "Epoch 1 of 50\n",
            "Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/3 [00:04<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-51eca2125552>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1} of {epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_epoch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_epoch_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mval_epoch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_epoch_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_epoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-b4ccce49c091>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-c8f0b5a24938>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# Flatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m32\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;31m# Feed to fully-connected layer to predict class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 24576]' is invalid for input of size 1153200"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "  \n",
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "  \n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
        "    \n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(),lr)\n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    \n",
        "    return history"
      ],
      "metadata": {
        "id": "comf9Y-MCF3z"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "opt_func = torch.optim.Adam\n",
        "lr = 0.001\n",
        "#fitting the model on training data and record the result after each epoch\n",
        "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "rl7pPv7wCJUE",
        "outputId": "30f5cdf7-279a-426e-da0b-74769156012b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-685305644a23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#fitting the model on training data and record the result after each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "WEIGHT_DECAY = 0.0005\n",
        "fine_tune = True"
      ],
      "metadata": {
        "id": "rujKXWvW9hat"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,dataloader):    \n",
        "    # training function\n",
        "\n",
        "    print('Training')\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_correct = 0\n",
        "    total=0\n",
        "    for batch, (X, y) in enumerate(tqdm(dataloader)):\n",
        "\n",
        "\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X)\n",
        "        loss = loss_fn(outputs, y)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        running_correct += (outputs.argmax(1) == y).type(torch.float).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    loss = running_loss/len(dataloader)\n",
        "    accuracy = 100.*running_correct/total\n",
        "    print('Train Loss: %.3f | Accuracy: %.3f'%(loss, accuracy))\n",
        "\n",
        "\n",
        "    #print(f\"Train Loss: {loss:.4f}, Train Acc: {accuracy:.2f}\")\n",
        "\n",
        "\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "id": "XPexxd9r-ra8"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#validation function\n",
        "def validate(model, dataloader):\n",
        "    print('Validating')\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_correct = 0\n",
        "    total=0\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # Compute prediction error\n",
        "            pred = model(X)\n",
        "            loss = loss_fn(pred, y)\n",
        "            running_loss += loss_fn(pred, y).item()        \n",
        "            running_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            total += y.size(0)\n",
        "        \n",
        "    loss = running_loss/len(dataloader)\n",
        "    accuracy = 100.*running_correct/total\n",
        "    #print(f'Val Loss: {loss:.4f}, Val Acc: {accuracy:.2f}')\n",
        "    print('Test Loss: %.3f | Accuracy: %.3f'%(loss, accuracy))\n",
        "\n",
        "\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "id": "Xbl8eAO2_Pxp"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=50\n",
        "\n",
        "\n",
        "train_loss , train_accuracy = [], []\n",
        "val_loss , val_accuracy = [], []\n",
        "print(f\"Training on {len(train_data)} examples, validating on {len(test_data)} examples...\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch+1} of {epochs}\")\n",
        "    train_epoch_loss, train_epoch_accuracy = train(cnn, trainLoader)\n",
        "    val_epoch_loss, val_epoch_accuracy = validate(cnn, testLoader)\n",
        "    train_loss.append(train_epoch_loss)\n",
        "    train_accuracy.append(train_epoch_accuracy)\n",
        "    val_loss.append(val_epoch_loss)\n",
        "    val_accuracy.append(val_epoch_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "Fh0V3FuU_X0u",
        "outputId": "a0dd7221-955d-469c-baa2-95bad513d621"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on 147 examples, validating on 50 examples...\n",
            "Epoch 1 of 50\n",
            "Training\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-4993e5c9c95b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1} of {epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_epoch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_epoch_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mval_epoch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_epoch_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_epoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-b4ccce49c091>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mrunning_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.001)\n",
        "\n",
        "save_path = \"model.pth\""
      ],
      "metadata": {
        "id": "Ya3VAhq36FvU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=50"
      ],
      "metadata": {
        "id": "W2DRFrZN6JnK"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,trainloader):    \n",
        "    # training function\n",
        "    for epoch in range(epochs):\n",
        "        print('Training')\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_correct = 0\n",
        "        for batch, (X, y) in enumerate(tqdm(trainloader)):\n",
        "\n",
        "\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X)\n",
        "            loss = loss_fn(outputs, y)\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "\n",
        "            running_correct += (outputs.argmax(1) == y).type(torch.float).sum().item()\n",
        "            \n",
        "            \n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "                        #running_loss += loss.item()\n",
        "\n",
        "            #running_correct += (outputs.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "\n",
        "        loss = running_loss/len(trainloader.dataset)\n",
        "        accuracy = 100. * running_correct/len(trainloader.dataset)\n",
        "\n",
        "        print(f\"Train Loss: {loss:.4f}, Train Acc: {accuracy:.2f}\")\n",
        "\n",
        "        return loss, accuracy\n"
      ],
      "metadata": {
        "id": "1S0Cf2Yg6OxG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#validation function\n",
        "def validate(model, dataloader):\n",
        "    print('Validating')\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_correct = 0\n",
        "    with torch.no_grad():\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # Compute prediction error\n",
        "            pred = model(X)\n",
        "            loss = loss_fn(pred, y)\n",
        "            running_loss += loss_fn(pred, y).item()        \n",
        "            running_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "        \n",
        "        loss = running_loss/len(dataloader.dataset)\n",
        "        accuracy = 100. * running_correct/len(dataloader.dataset)\n",
        "        print(f'Val Loss: {loss:.4f}, Val Acc: {accuracy:.2f}')\n",
        "        \n",
        "        return loss, accuracy"
      ],
      "metadata": {
        "id": "w2A3fTHi6aa3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, dataloader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            total += y.size(0)\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    return correct, total"
      ],
      "metadata": {
        "id": "FRWXVddq6cGJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=50\n",
        "\n",
        "\n",
        "train_loss , train_accuracy = [], []\n",
        "val_loss , val_accuracy = [], []\n",
        "print(f\"Training on {len(train_data)} examples, validating on {len(val_data)} examples...\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch+1} of {epochs}\")\n",
        "    train_epoch_loss, train_epoch_accuracy = train(model, trainLoader)\n",
        "    val_epoch_loss, val_epoch_accuracy = validate(model, valLoader)\n",
        "    train_loss.append(train_epoch_loss)\n",
        "    train_accuracy.append(train_epoch_accuracy)\n",
        "    val_loss.append(val_epoch_loss)\n",
        "    val_accuracy.append(val_epoch_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1uEhPfb6lEW",
        "outputId": "9d5939fd-d0d9-42b8-a1f0-af192c982bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on 147 examples, validating on 50 examples...\n",
            "Epoch 1 of 50\n",
            "Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Function to show the images\n",
        "def imageshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Function to test the model with a batch of images and show the labels predictions\n",
        "def testBatch():\n",
        "    # get batch of images from the test DataLoader  \n",
        "    images, labels = next(iter(testLoader))\n",
        "\n",
        "    # show all images as one image grid\n",
        "    imageshow(torchvision.utils.make_grid(images))\n",
        "   \n",
        "    # Show the real labels on the screen \n",
        "    print('Real labels: ', ' '.join('%5s' % classes[labels[j]] \n",
        "                               for j in range(batch_size)))\n",
        "     # Let's see what if the model identifiers the  labels of those example\n",
        "    images=images.to(device)\n",
        "    outputs = model(images)\n",
        "    \n",
        "    # We got the probability for every 10 labels. The highest (max) probability should be correct label\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    \n",
        "    # Let's show the predicted labels on the screen to compare with the real ones\n",
        "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] \n",
        "                              for j in range(batch_size)))\n",
        "    "
      ],
      "metadata": {
        "id": "Kyn_izvi7bA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "testBatch()"
      ],
      "metadata": {
        "id": "CwXmwAOL7lP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy plots\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.subplot(121)\n",
        "plt.plot(train_accuracy, color='green', label='train accuracy')\n",
        "plt.plot(val_accuracy, color='blue', label='validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "# plt.savefig('../outputs/plots/accuracy.png')"
      ],
      "metadata": {
        "id": "ThXyG67V7mSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss plots\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.subplot(121)\n",
        "plt.plot(train_loss, color='orange', label='train loss')\n",
        "plt.plot(val_loss, color='red', label='validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "# plt.savefig('../outputs/plots/loss.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4JPlbkSK7qdj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}